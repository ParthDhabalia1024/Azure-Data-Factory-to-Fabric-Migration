import os
import subprocess
from collections import defaultdict
from typing import Optional, Dict, List, Tuple, Any

import streamlit as st
from azure.identity import InteractiveBrowserCredential

# Import from modular components
from Migration.azure_common import (
    list_subscriptions,
    list_resource_groups,
    list_data_factories,
    list_rg_resources,
)

from Migration.adf_components import (
    fetch_components_for_factory,
    fetch_activity_rows_for_factory,
    list_linked_services_for_factory,
    list_datasets_for_factory,
)

from Migration.sql_server import (
    list_sql_servers,
    list_sql_databases_for_server,
    list_sql_usage_for_database_from_adf,
    _list_sql_tables_via_pyodbc,
    _get_db_properties_via_pyodbc,
    _list_sql_views_via_pyodbc,
    _list_sql_table_overview_via_pyodbc,
)

from Migration.data_storage import (
    list_storage_accounts,
    list_blob_containers,
    list_adls_filesystems,
    is_hns_enabled,
    list_adls_top_level_directories,
    list_adls_files_in_directory,
    list_top_level_folders,
    list_files_in_folder,
    sample_blob_paths,
    sample_adls_paths,
)

from Migration.migration_score import (
    score_component_parity,
    score_non_migratable,
    score_connectivity,
    score_orchestration,
)

from Migration.utilities import _normalize_type
from Migration.constants import CONTROL_ACTIVITY_TYPES
from Migration.ui_config import apply_custom_theme, render_header_with_logo




def main() -> None:
    st.set_page_config(page_title="ADF to Fabric Migration Tool | OnPoint Insights", page_icon="üî∑", layout="wide")
    
    # Apply custom OnPoint Insights theme
    apply_custom_theme()
    
    # Get logo path
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    UTILS_DIR = os.path.join(BASE_DIR, "utils")

    logo_path = os.path.join(UTILS_DIR, "logo.png")

    
    # Custom header with branding and logo
    render_header_with_logo(
        "Azure Data Factory to Fabric Migration",
        "Powered by OnPoint Insights",
        logo_path=logo_path
    )
    st.markdown("---")
    st.info("Sign in to Azure, select your subscription, resource group, and Data Factory, then migrate pipelines to Microsoft Fabric.")

    if "credential" not in st.session_state:
        st.session_state.credential = None

    # Sign-in section
    with st.container(border=True):
        st.subheader("üîê Sign in to Azure")
        col1, col2 = st.columns([1, 3])
        with col1:
            login_clicked = st.button("üîë Sign In with Azure", type="primary", use_container_width=True)
        with col2:
            st.markdown("**Status:** " + ("‚úÖ Signed in" if st.session_state.credential else "‚ùå Not signed in"))
        if login_clicked or st.session_state.credential is None:
            try:
                cred = InteractiveBrowserCredential()
                # Test by listing subscriptions to complete device login
                subs = list_subscriptions(_credential=cred)
                st.session_state.credential = cred
                st.success("‚úÖ Signed in successfully.")
            except Exception as e:
                st.error(f"‚ùå Sign-in failed: {e}")
                return

    credential: Optional[InteractiveBrowserCredential] = st.session_state.credential
    if credential is None:
        st.stop()

    # Subscription selection
    with st.container(border=True):
        st.subheader("üìã Select Subscription")
        try:
            subs = list_subscriptions(_credential=credential)
        except Exception as e:
            st.error(f"Failed to list subscriptions: {e}")
            st.stop()
        sub_labels = [f"{name} ({sid})" for name, sid in subs]
        sub_idx = st.selectbox("Subscription", options=list(range(len(subs))), format_func=lambda i: sub_labels[i] if subs else "", index=0 if subs else None)
        if subs:
            subscription_id = subs[sub_idx][1]
        else:
            st.warning("No subscriptions available.")
            st.stop()

    # Resource group selection
    with st.container(border=True):
        st.subheader("üìÅ Select Resource Group")
        try:
            rgs = list_resource_groups(_credential=credential, subscription_id=subscription_id)
        except Exception as e:
            st.error(f"Failed to list resource groups: {e}")
            st.stop()
        if not rgs:
            st.warning("No resource groups in this subscription.")
            st.stop()
        rg_name = st.selectbox("Resource group", options=rgs, index=0)
        try:
            res_rows = list_rg_resources(
                _credential=credential,
                subscription_id=subscription_id,
                resource_group=rg_name,
            )
            if res_rows:
                st.caption(f"Resources in '{rg_name}' ({len(res_rows)} found)")
                st.dataframe(res_rows, hide_index=True, width="stretch")
                                # -------------------------------
                

            else:
                st.info("No resources found in this resource group.")
        except Exception as e:
            st.warning(f"Could not list resources in '{rg_name}': {e}")

        # ========== DATA FACTORIES SECTION ==========
        if "selected_df" not in st.session_state:
            st.session_state.selected_df = None
        selected_df: Optional[str] = st.session_state.selected_df
        clicked_df: Optional[str] = None
        try:
            factories = list_data_factories(
                _credential=credential,
                subscription_id=subscription_id,
                resource_group=rg_name,
            )
        except Exception as e:
            factories = []
            st.warning(f"Could not list data factories: {e}")
        
        if factories:
            st.caption("üìä Open a Data Factory:")
            cols = st.columns(min(4, max(1, len(factories))))
            for i, fac in enumerate(factories):
                if cols[i % len(cols)].button(fac, key=f"open_df_{fac}"):
                    clicked_df = fac
        
        if clicked_df:
            st.session_state.selected_df = clicked_df
            selected_df = clicked_df
        
        if selected_df and selected_df not in factories:
            st.session_state.selected_df = None
            selected_df = None
        
        if selected_df:
            st.markdown("---")
            st.subheader(f"üîç Data Factory: {selected_df}")

            # Fetch components and linked services
            try:
                act_rows = fetch_activity_rows_for_factory(credential, subscription_id, rg_name, selected_df)
            except Exception as e:
                st.error(f"Failed to fetch components: {e}")
                act_rows = []
            
            try:
                ls_rows = list_linked_services_for_factory(credential, subscription_id, rg_name, selected_df)
                ls_types = [row.get("LinkedServiceType", "") for row in ls_rows]
            except Exception as e:
                ls_rows = []
                ls_types = []

            # 1) Pipelines and Activities
            with st.container(border=True):
                st.subheader("üìã Pipelines and Activities")
                if act_rows:
                    st.dataframe(act_rows, width="stretch", hide_index=True)
                else:
                    st.info("No components found.")

            # 2) Migration Scoring
            with st.container(border=True):
                st.subheader("üìà Migration Scoring (Fabric Readiness Assessment)")
                grouped: Dict[Tuple[str, str], List[Dict[str, str]]] = defaultdict(list)
                for r in act_rows:
                    grouped[(r.get("Factory", ""), r.get("PipelineName", ""))].append(r)
                score_rows: List[Dict[str, Any]] = []
                for (fac, pipe), items in grouped.items():
                    total_acts = len(items)
                    non_migratable = sum(1 for it in items if (it.get("Migratable") or "").lower() == "no")
                    control_acts = 0
                    for it in items:
                        nt = _normalize_type(it.get("ActivityType"))
                        if nt in CONTROL_ACTIVITY_TYPES:
                            control_acts += 1
                    parity_score = score_component_parity(total_acts, non_migratable)
                    non_mig_score = score_non_migratable(non_migratable)
                    connectivity_score = score_connectivity(ls_types)
                    orchestration_score = score_orchestration(total_acts, control_acts)
                    total = parity_score + non_mig_score + connectivity_score + orchestration_score
                    if 3 in (parity_score, non_mig_score, connectivity_score, orchestration_score):
                        band = "üî¥ Hard"
                    elif total <= 4:
                        band = "üü¢ Easy"
                    elif total <= 8:
                        band = "üü° Medium"
                    else:
                        band = "üî¥ Hard"
                    score_rows.append({
                        "Factory": fac,
                        "Pipeline": pipe,
                        "Component Parity": parity_score,
                        "Non-Migratable": non_mig_score,
                        "Connectivity": connectivity_score,
                        "Orchestration": orchestration_score,
                        "Total Score": total,
                        "Difficulty": band,
                        "Activities": total_acts,
                        "Non-Migratable Count": non_migratable,
                    })
                if score_rows:
                    st.dataframe(score_rows, width="stretch", hide_index=True)
                else:
                    st.info("No pipelines to score.")

            # 3) Linked Services
            with st.container(border=True):
                st.subheader("üîó Linked Services")
                if ls_rows:
                    st.dataframe(ls_rows, width="stretch", hide_index=True)
                else:
                    st.info("No linked services found.")

            # 4) Datasets
            with st.container(border=True):
                st.subheader("üì¶ Datasets")
                try:
                    ds_rows = list_datasets_for_factory(credential, subscription_id, rg_name, selected_df)
                except Exception as e:
                    ds_rows = []
                    st.error(f"Failed to list datasets: {e}")
                if ds_rows:
                    st.dataframe(ds_rows, width="stretch", hide_index=True)
                else:
                    st.info("No datasets found.")

            # 5) Migration to Fabric
            with st.container(border=True):
                st.subheader("üöÄ Migrate to Microsoft Fabric")
                pipeline_names = sorted({row.get("Pipeline") for row in score_rows if row.get("Pipeline")})
                if not pipeline_names:
                    st.info("No pipelines available to migrate for this Data Factory.")
                else:
                    migrate_all = st.checkbox(
                        "Migrate all pipelines",
                        value=True,
                        key=f"migrate_all_{selected_df}",
                    )
                    if migrate_all:
                        pipelines_to_migrate = pipeline_names
                    else:
                        pipelines_to_migrate = st.multiselect(
                            "Select pipelines to migrate",
                            options=pipeline_names,
                            default=pipeline_names,
                            key=f"pipelines_to_migrate_{selected_df}",
                        )

                    # Workspace ID input
                    workspace_id = st.text_input(
                        "Fabric Workspace ID",
                        placeholder="Enter your Fabric Workspace ID (UUID format)",
                        key=f"workspace_id_{selected_df}",
                    )

                    run_migration = st.button(
                        "üîÑ Migrate Selected Pipelines to Fabric",
                        type="primary",
                        key=f"run_migration_{selected_df}",
                    )
                    if run_migration:
                        if not pipelines_to_migrate:
                            st.warning("Please select at least one pipeline to migrate.")
                        elif not workspace_id:
                            st.warning("Please enter a Fabric Workspace ID.")
                        else:
                            script_path = os.path.join(UTILS_DIR, "adf_to_fabric_migration.ps1")
                            resolutions_file = os.path.join(UTILS_DIR, "resolutions.json")
                            region = "prod"
                            cmd = [
                                "pwsh",
                                "-File",
                                script_path,
                                "-FabricWorkspaceId",
                                workspace_id,
                                "-ResolutionsFile",
                                resolutions_file,
                                "-Region",
                                region,
                                "-SubscriptionId",
                                subscription_id,
                                "-ResourceGroupName",
                                rg_name,
                                "-DataFactoryName",
                                selected_df,
                                "-PipelineNames",
                                ",".join(pipelines_to_migrate),
                            ]
                            try:
                                with st.spinner("Running migration in PowerShell (this may take a few minutes)..."):
                                    result = subprocess.run(
                                        cmd,
                                        capture_output=True,
                                        text=True,
                                    )
                            except FileNotFoundError:
                                st.error("Failed to start PowerShell 7 (pwsh). Ensure PowerShell 7 is installed and available in PATH.")
                            except Exception as exc:
                                st.error(f"Failed to launch migration script: {exc}")
                            else:
                                if result.returncode == 0:
                                    st.success("‚úÖ Migration script completed. Check Microsoft Fabric and the Logs folder for details.")
                                else:
                                    st.error(f"‚ùå Migration script exited with code {result.returncode}.")
                                if result.stdout:
                                    st.caption("PowerShell output:")
                                    st.code(result.stdout, language="powershell")
                                if result.stderr:
                                    st.caption("PowerShell errors:")
                                    st.code(result.stderr, language="powershell")

        # ========== SQL SERVERS SECTION ==========
        if "selected_sql_server" not in st.session_state:
            st.session_state.selected_sql_server = None
        selected_sql_server: Optional[str] = st.session_state.selected_sql_server
        clicked_sql_server: Optional[str] = None
        try:
            sql_servers = list_sql_servers(credential, subscription_id, rg_name)
        except Exception as e:
            sql_servers = []
            st.warning(f"Could not list SQL servers: {e}")
        
        if sql_servers:
            st.caption("üóÑÔ∏è Open an Azure SQL Server:")
            cols_sql = st.columns(min(4, max(1, len(sql_servers))))
            for i, srv in enumerate(sql_servers):
                if cols_sql[i % len(cols_sql)].button(srv, key=f"open_sql_{srv}"):
                    clicked_sql_server = srv
        
        if clicked_sql_server:
            st.session_state.selected_sql_server = clicked_sql_server
            selected_sql_server = clicked_sql_server
        
        if selected_sql_server and selected_sql_server not in sql_servers:
            st.session_state.selected_sql_server = None
            selected_sql_server = None
        
        if selected_sql_server:
            st.markdown("---")
            st.subheader(f"üîç SQL Server: {selected_sql_server}")
            
            try:
                db_rows = list_sql_databases_for_server(
                    _credential=credential,
                    subscription_id=subscription_id,
                    resource_group=rg_name,
                    server_name=selected_sql_server,
                )
            except Exception as e:
                db_rows = []
                st.error(f"Failed to list databases: {e}")
            
            if db_rows:
                st.caption("Databases on this server")
                st.dataframe(db_rows, hide_index=True, width="stretch")

                # Per-database buttons
                if "selected_sql_database" not in st.session_state:
                    st.session_state.selected_sql_database = None
                selected_sql_database: Optional[str] = st.session_state.selected_sql_database
                clicked_db: Optional[str] = None
                db_names = [row.get("Database", "") for row in db_rows if row.get("Database")]
                
                if db_names:
                    st.caption("üìÇ Open a Database:")
                    db_cols = st.columns(min(4, max(1, len(db_names))))
                    for i, db_name in enumerate(db_names):
                        if db_cols[i % len(db_cols)].button(db_name, key=f"open_db_{selected_sql_server}_{db_name}"):
                            clicked_db = db_name
                
                if clicked_db:
                    st.session_state.selected_sql_database = clicked_db
                    selected_sql_database = clicked_db
                
                if selected_sql_database and selected_sql_database not in db_names:
                    st.session_state.selected_sql_database = None
                    selected_sql_database = None
                
                if selected_sql_database:
                    st.markdown("---")
                    st.subheader(f"üìä Database: {selected_sql_database}")
                    
                    default_db_conn_hint = (
                        "DRIVER={ODBC Driver 18 for SQL Server};"
                        f"SERVER={selected_sql_server};"
                        f"DATABASE={selected_sql_database};"
                        "UID=your-user;PWD=your-password;Encrypt=yes;TrustServerCertificate=no;"
                    )
                    db_conn_str = st.text_input(
                        "SQL Connection String (for listing tables, views, etc.)",
                        value="",
                        placeholder=default_db_conn_hint,
                        key=f"db_conn_{selected_sql_server}_{selected_sql_database}",
                    )
                    
                    if db_conn_str:
                        if st.button("üìã Load Database Components", key=f"btn_list_tables_{selected_sql_server}_{selected_sql_database}"):
                            # Database properties
                            db_info = _get_db_properties_via_pyodbc(db_conn_str)
                            if db_info.get("error"):
                                st.error(f"‚ùå {db_info['error']}")
                            else:
                                props = db_info.get("properties") or {}
                                if props:
                                    st.markdown("#### üóÇÔ∏è Database Properties")
                                    st.dataframe([props], hide_index=True, width="stretch")
                                    st.divider()

                            # Views
                            view_info = _list_sql_views_via_pyodbc(db_conn_str)
                            if view_info.get("error"):
                                st.error(f"‚ùå {view_info['error']}")
                            else:
                                views = view_info.get("views") or []
                                if views:
                                    st.markdown("#### üëÅÔ∏è Views")
                                    st.dataframe(views, hide_index=True, width="stretch")
                                    st.divider()
                                else:
                                    st.info("No views found in this database.")

                            # Tables with metadata
                            st.markdown("#### üìë Tables with Row Counts & Constraints")
                            tbl_info = _list_sql_table_overview_via_pyodbc(db_conn_str)
                            if tbl_info.get("error"):
                                st.error(f"‚ùå Error loading tables: {tbl_info['error']}")
                            else:
                                tbl_rows = tbl_info.get("tables") or []
                                if tbl_rows:
                                    st.dataframe(tbl_rows, hide_index=True, width="stretch")
                                else:
                                    st.info("‚ÑπÔ∏è No tables found in this database.")
                    else:
                        st.info("üí° Enter a SQL connection string above to load database components.")
            else:
                st.info("No databases found on this server.")

        # ========== STORAGE ACCOUNTS SECTION ==========
        if "selected_sa" not in st.session_state:
            st.session_state.selected_sa = None
        selected_sa: Optional[str] = st.session_state.selected_sa
        previous_sa: Optional[str] = selected_sa
        clicked_sa: Optional[str] = None
        try:
            storage_accounts = list_storage_accounts(
                _credential=credential,
                subscription_id=subscription_id,
                resource_group=rg_name,
            )
        except Exception as e:
            storage_accounts = []
            st.warning(f"Could not list storage accounts: {e}")
        if storage_accounts:
            st.caption("Open a Storage Account:")
            cols_sa = st.columns(min(4, max(1, len(storage_accounts))))
            for i, sa in enumerate(storage_accounts):
                if cols_sa[i % len(cols_sa)].button(sa, key=f"open_sa_{sa}"):
                    clicked_sa = sa
        if clicked_sa:
            st.session_state.selected_sa = clicked_sa
            selected_sa = clicked_sa
        if selected_sa and selected_sa not in storage_accounts:
            st.session_state.selected_sa = None
            selected_sa = None
        if selected_sa != previous_sa:
            st.session_state.storage_selection = {}
        if selected_sa:
            st.subheader(f"Storage account: {selected_sa}")
            # Account-level summary
            try:
                hns = is_hns_enabled(credential, subscription_id, rg_name, selected_sa)
            except Exception as e:
                hns = False
                st.warning(f"Could not determine HNS setting: {e}")
            try:
                containers = list_blob_containers(credential, subscription_id, rg_name, selected_sa)
            except Exception as e:
                containers = []
                st.error(f"Failed to list containers/filesystems: {e}")
            summary_rows = [{
                "Account": selected_sa,
                "HNSEnabled": "Yes" if hns else "No",
                "ContainerCount": len(containers),
            }]
            st.dataframe(summary_rows, hide_index=True, width="stretch")

            st.markdown("**Browse folders:**")
            if "storage_selection" not in st.session_state:
                st.session_state.storage_selection = {}
            selection_state: Dict[str, Dict[str, Optional[str]]] = st.session_state.storage_selection

            for c in containers:
                key = f"storage_{selected_sa}_{c}"
                sel = selection_state.setdefault(key, {"folder": None})
                try:
                    if hns:
                        top_dirs = list_adls_top_level_directories(credential, selected_sa, c)
                        folders = [row.get("Folder") for row in top_dirs if row.get("Folder")]
                        with st.expander(f"Folders in Container: {c}", expanded=bool(sel.get("folder"))):
                            if folders:
                                folder_cols = st.columns(min(4, max(1, len(folders))))
                                for idx, folder in enumerate(folders):
                                    if folder_cols[idx % len(folder_cols)].button(folder, key=f"{key}_folder_{folder}"):
                                        sel["folder"] = folder
                            else:
                                st.info("No top-level folders detected.")
                            if sel.get("folder"):
                                st.caption(f"Selected folder: {sel['folder']}")
                                try:
                                    files = list_adls_files_in_directory(credential, selected_sa, c, sel["folder"], max_items=200)
                                    if files:
                                        st.write(f"Files in {sel['folder']} (up to 200)")
                                        st.dataframe(files, hide_index=True, width="stretch")
                                    else:
                                        st.info("No files found in this folder.")
                                except Exception as e:
                                    st.warning(f"Failed to list files: {e}")
                    else:
                        top_folders = list_top_level_folders(credential, selected_sa, c)
                        with st.expander(f"Folders in {c}", expanded=bool(sel.get("folder"))):
                            if top_folders:
                                folder_cols = st.columns(min(4, max(1, len(top_folders))))
                                for idx, folder in enumerate(top_folders):
                                    if folder_cols[idx % len(folder_cols)].button(folder, key=f"{key}_folder_{folder}"):
                                        sel["folder"] = folder
                            else:
                                st.info("No top-level folders detected.")
                            if sel.get("folder"):
                                st.caption(f"Selected folder: {sel['folder']}")
                                try:
                                    files = list_files_in_folder(credential, selected_sa, c, sel["folder"], max_items=200)
                                    if files:
                                        st.write(f"Files in {sel['folder']} (up to 200)")
                                        st.dataframe(files, hide_index=True, width="stretch")
                                    else:
                                        st.info("No files found in this folder.")
                                except Exception as e:
                                    st.warning(f"Failed to list files: {e}")
                except Exception as e:
                    st.warning(f"Failed to browse container '{c}': {e}")


if __name__ == "__main__":
    main()
